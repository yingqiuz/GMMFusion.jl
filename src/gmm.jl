@with_kw mutable struct GMMBatch{T<:Real}
    K::Int
    X::AbstractArray{T}
    index::AbstractArray{Int} = findall(x -> x>1f-3, std(X, dims=1)[:])
    n::Int = size(X, 1)
    d::Int = size(X, 2)
    R::AbstractArray{T} = fill(1f0 / K, n, K)
    nk::AbstractArray{T} = vec(sum(R, dims=1))
    w::AbstractArray{T} = nk ./ n
    Î¼::AbstractArray{T} = X' * R
    Î£::AbstractArray = [cholesky!(Hermitian(cov(X) + I * 1f-6)) for k in 1:K]
    llh::AbstractArray{T} = convert(Array{eltype(X)}, fill(-Inf32, 10))
    llhmap::AbstractArray{T} = zeros(eltype(X), n, K)
end

function MixGauss!(
    model::GMMBatch{T}; tol::T=convert(T, 1f-6), maxiter::Int=1000
) where T <: Real
    # likelihood vector
    L = fill(-Inf32, maxiter)
    # progress bar
    prog = ProgressUnknown("Running Gaussian mixture model...", dt=0.1, spinner=true)
    iter = 1
    Xo = deepcopy(model.X)
    while iter < maxiter
        iter += 1
        L[iter] = batch(model, Xo)
        incr = (L[iter] - L[iter-1]) / L[iter-1]
        ProgressMeter.next!(
            prog; showvalues = [(:iter, iter-1), (:incr, incr)]
        )
        if abs(incr) < tol
            ProgressMeter.finish!(prog)
            model.llh = copy(L[2:iter])
            return model
        end
    end
    ProgressMeter.finish!(prog)
    iter == maxiter || @warn "Not converged after $(maxiter) steps."
    model.llh = copy(L[2:iter])
    return model
end

function batch(model::GMMBatch{T}, Xo::AbstractArray{T}) where T <: Real
    # M step
    maximise!(model, Xo)
    # E step
    expect!(model, Xo)
end

function maximise!(
    model::GMMBatch{T}, Xo
) where T <: Real
    # posterior parameters
    sum!(model.nk, model.R')
    copyto!(model.w, model.nk ./ model.n)
    @debug "model.R" model.R
    # update Î¼
    mul!(model.Î¼, model.X', model.R)
    model.Î¼ ./= model.nk'
    # update Î£
    @inbounds for k âˆˆ 1:model.K
        copyto!(Xo, model.X)
        Xo .-= transpose(view(model.Î¼, :, k))
        Xo .*= sqrt.(view(model.R, :, k))
        model.Î£[k] = cholesky!(Hermitian(Xo' * Xo ./ model.nk[k]) + I * 1f-5)
    end
end

function expect!(model::GMMBatch{T}, Xo::AbstractArray{T}) where T<:Real
    @inbounds for k âˆˆ 1:model.K
        Rk = view(model.R, :, k)
        Î¼k = view(model.Î¼, :, k)
        # Gauss llh
        copyto!(Xo, model.X)
        Xo .-= Î¼k'
        copyto!(Rk, diag((Xo / model.Î£[k]) * Xo'))
        Rk .+= logdet(model.Î£[k]) + model.d * log(2Ï€)
    end
    model.R .*= -0.5f0
    model.R .+= @avx log.(model.w')
    @debug "R" model.R
    #copyto!(model.llhmap, Flux.logsumexp(model.R, dims=2))
    l = sum(Flux.logsumexp(model.R, dims=2)) / model.n
    #@info "model.R" model.R maximum(model.R)
    Flux.softmax!(model.R, dims=2)
    @debug "R" model.R
    return l
end

function predict(
    model::GMM{T}, 
    Xtest::AbstractArray{T}
) where T <: Real
    K = model.K
    ntest = size(Xtest, 1)
    Rtest = zeros(T, ntest, K)
    covmat = zeros(T, ntest, ntest)
    Xo = copy(Xtest)
    E!(Rtest, Xtest, model.w, model.Î¼, model.Î£, Xo, covmat)
    return Rtest
end

function EM(
    X::AbstractArray{T}, K::Int;
    init::Union{Symbol, SeedingAlgorithm, AbstractVector{<:Integer}}=:kmpp,
    tol::T=convert(T, 1e-6), maxiter::Int=1000
) where T <: Real
    n, d = size(X)
    # init 
    R = kmeans(X', K; init=init, tol=tol, maxiter=maxiter)
    w = convert(Array{T}, counts(R) ./ n)  # cluster size
    Î¼ = copy(R.centers)
    Î£ = [cholesky!(cov(X)) for k âˆˆ 1:K]
    R = [x == k ? 1 : 0 for x âˆˆ assignments(R), k âˆˆ 1:K]
    #model = GMM(d, K, ones(T, K) ./ K, Î¼, Î£)
    EM!(convert(Array{T}, R), copy(X), w, Î¼, Î£; 
        tol=tol, maxiter=maxiter)
    return GMM(K, d, w, Î¼, Î£)
end

function EM!(
    R::AbstractArray{T}, X::AbstractArray{T}, w::AbstractVector{T}, 
    Î¼::AbstractMatrix{T}, Î£::AbstractVector{A} where A <: Cholesky{T, Matrix{T}};
    tol::T=convert(T, 1e-6), maxiter::Int=1000
) where T <: Real
    n, d = size(X)
    n2, K = size(R)
    n == n2 || throw(DimensionMismatch("Dimension of X and R mismatch."))
    # allocate memory for temporary matrices
    Xo = copy(X)
    covmat = zeros(T, n, n)

    # allocate memory for llh
    llh = Vector{T}(undef, maxiter)
    fill!(llh, -Inf32)
    prog = ProgressUnknown("Running EM...", dt=0.1, spinner=true)
    incr = NaN32
    for iter âˆˆ 2:maxiter
        # E-step
        ProgressMeter.next!(
            prog; spinner="ðŸ•ðŸ•‘ðŸ•’ðŸ•“ðŸ•”ðŸ••ðŸ•–ðŸ•—ðŸ•˜ðŸ•™ðŸ•šðŸ•›",
            showvalues = [(:iter, iter-1), (:incr, incr)]
        )
        @debug "R" R
        @debug "w" w
        @debug "Î¼" Î¼
        @debug "Î£" Î£
        llh[iter] = E!(R, X, w, Î¼, Î£, Xo, covmat)
        # M-step
        M!(w, Î¼, Î£, R, X, Xo)
        incr = (llh[iter] - llh[iter-1]) / llh[iter-1]
        #@info "iteration $(iter-1), incr" incr
        if abs(incr) < tol || iter == maxiter
            ProgressMeter.finish!(prog)
            iter != maxiter || @warn "Not converged after $(maxiter) steps"
            return R
        end
    end
end

function E!(
    R::AbstractArray{T}, X::AbstractArray{T}, w::AbstractVector{T},
    Î¼::AbstractArray{T}, Î£::AbstractVector{A} where A <: Cholesky{T, Matrix{T}},
    Xo::AbstractArray{T}, covmat::AbstractArray{T}
) where T <: Real
    n, K = size(R)
    @inbounds for k âˆˆ 1:K
        expectation!(
            view(R, :, k), X, Xo, covmat,
            view(Î¼, :, k), Î£[k]
        )
    end
    @debug "R" R
    @avx R .+= log.(w')
    @debug "R" R
    llh = logsumexp(R, dims=2)
    R .-= llh
    @avx R .= exp.(R)
    @debug "R" R
    return sum(llh) / n
end

function expectation!(
    Rk::AbstractVector{T},
    X::AbstractArray{T},
    Xo::AbstractArray{T},
    covmat::AbstractMatrix{T},
    Î¼::AbstractVector{T},
    C::Cholesky{T, Matrix{T}}
) where T <: Real
    n, d = size(X)
    copyto!(Xo, X)
    Xo .-= Î¼'
    #@debug "X Xo" X sum(Xo, dims=1)
    #C = cholesky!(Hermitian(Î£))
    fill!(Rk, -logdet(C) / 2 - log(2Ï€) * d / 2)
    mul!(covmat, Xo, C \ transpose(Xo))
    @debug "covmat" diag(covmat)
    Rk .-= diag(covmat) ./ 2
end

function M!(
    w::AbstractVector{T}, Î¼::AbstractMatrix{T}, Î£::AbstractVector{A} where A <: Cholesky{T, Matrix{T}}, 
    R::AbstractMatrix{T}, X::AbstractMatrix{T}, Xo::AbstractMatrix{T}
) where T <: Real
    n, K = size(R)
    # udpate parameters
    sum!(w, R')
    #w .= vec(sum(R, dims=1)) # remember to div by n
    @debug "w" w
    mul!(Î¼, transpose(X), R)
    Î¼ ./= w'
    # update Î£
    @inbounds for k âˆˆ 1:K
        copy!(Xo, X)
        Xo .-= transpose(view(Î¼, :, k))
        Xo .*= sqrt.(view(R, :, k))
        Î£[k] = cholesky!(Xo' * Xo ./ w[k] + I * 1f-6)
    end
    w ./= n
end

function EM(
    R::KmeansResult{Matrix{T}, T, Int}, X::AbstractArray{T}, K::Int;
    tol::T=convert(T, 1e-6), maxiter::Int=1000
) where T <: Real
    n, d = size(X)
    # init
    a = assignments(R)
    Î¼ = Matrix{T}(undef, d, K)
    for k âˆˆ 1:K
        Î¼[:, k] .= mean(X[findall(x -> x == k, a), :], dims=1)[:]
    end
    Î£ = [cholesky!(cov(X)) for k âˆˆ 1:K]
    w = convert(Array{T}, counts(R) ./ n)  # cluster size
    R = [x == k ? 1 : 0 for x âˆˆ a, k âˆˆ 1:K]
    #model = GMM(d, K, ones(T, K) ./ K, Î¼, Î£)
    EM!(convert(Array{T}, R), copy(X), w, Î¼, Î£; 
        tol=tol, maxiter=maxiter)
    return GMM(K, d, w, Î¼, Î£)
end